# Fine-Tuning Techniques for Language Models

This contains implementations of three different fine-tuning techniques for language models: LoRA (Low-Rank Adaptation), Prompt Tuning, and Traditional Fine-Tuning. The goal is to compare the performance and efficiency of these methods in adapting large language models for specific tasks.

## Directory Structure

- **lora_finetuning.py**: Script for implementing LoRA fine-tuning.
- **prompt_tuning.py**: Script for implementing prompt tuning.
- **traditional_finetuning.py**: Script for implementing traditional fine-tuning.

- **saved_models/**: This folder contains the saved models after fine-tuning. You can load these models for inference or further training.
  
- **finetuning_notebooks/**: This folder contains Jupyter notebooks that provide interactive environments for experimenting with the fine-tuning techniques. The notebooks include detailed explanations, results, and visualizations.

## To run:

python3 lora_finetuning.py
python3 prompt_tuning.py
python3 traditional_finetuning.py

Models at: https://drive.google.com/drive/folders/17E1Y9q1XMHosmzAqfYl-PrTZXYVTiTQg?usp=share_link
